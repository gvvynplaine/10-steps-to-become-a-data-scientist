{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a8f9622945156d6337ba73c481da2de7efef7384"
   },
   "source": [
    "### <div style=\"text-align: center\">A Comprehensive Machine Learning Workflow with Python </div>\n",
    "\n",
    "<div style=\"text-align: center\">There are plenty of <b>courses and tutorials</b> that can help you learn machine learning from scratch but here in <b>Kaggle</b>, I want to solve <font color=\"red\"><b>Titanic Competition</b></font>  a popular machine learning dataset as a comprehensive workflow with python packages. \n",
    "After reading, you can use this workflow to solve other real problems and use it as a template to deal with <b>machine learning</b> problems.</div>\n",
    "<div style=\"text-align:center\">last update: <b>09/07/2019</b></div>\n",
    "\n",
    "\n",
    "\n",
    "> You are reading **10 Steps to Become a Data Scientist** and are now in the 9th step : \n",
    "\n",
    "1. [Leren Python](https://www.kaggle.com/mjbahmani/the-data-scientist-s-toolbox-tutorial-1)\n",
    "2. [Python Packages](https://www.kaggle.com/mjbahmani/the-data-scientist-s-toolbox-tutorial-2)\n",
    "3. [Mathematics and Linear Algebra](https://www.kaggle.com/mjbahmani/linear-algebra-for-data-scientists)\n",
    "4. [Programming &amp; Analysis Tools](https://www.kaggle.com/mjbahmani/20-ml-algorithms-15-plot-for-beginners)\n",
    "5. [Big Data](https://www.kaggle.com/mjbahmani/a-data-science-framework-for-quora)\n",
    "6. [Data visualization](https://www.kaggle.com/mjbahmani/top-5-data-visualization-libraries-tutorial)\n",
    "7. [Data Cleaning](https://www.kaggle.com/mjbahmani/machine-learning-workflow-for-house-prices)\n",
    "8. [How to solve a Problem?](https://www.kaggle.com/mjbahmani/the-data-scientist-s-toolbox-tutorial-2)\n",
    "9. <font color=\"red\">You are in the ninth step</font>\n",
    "10. [Deep Learning](https://www.kaggle.com/mjbahmani/top-5-deep-learning-frameworks-tutorial)\n",
    "\n",
    "---------------------------------------------------------------------\n",
    "You can fork and run this kernel on <font color=\"red\">GitHub</font>:\n",
    "\n",
    "> ###### [ GitHub](https://github.com/mjbahmani/10-steps-to-become-a-data-scientist)\n",
    "\n",
    "-------------------------------------------------------------------------------------------------------------\n",
    " **I hope you find this kernel helpful and some <font color=\"red\"><b>UPVOTES</b></font> would be very much appreciated.**\n",
    " \n",
    " -----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cda11210a88d6484112cbe2c3624225328326c6a"
   },
   "source": [
    " <a id=\"top\"></a> <br>\n",
    "## Notebook  Content\n",
    "1. [Introduction](#1)\n",
    "     1. [Courses](#11)\n",
    "     1. [Kaggle kernels](#12)\n",
    "     1. [Ebooks](#13)\n",
    "     1. [CheatSheet](#14)\n",
    "1. [Machine learning](#2)\n",
    "    1. [Machine learning workflow](#21)\n",
    "    1. [Real world Application Vs Competitions](#22)\n",
    "1. [Problem Definition](#3)\n",
    "    1. [Problem feature](#31)\n",
    "        1. [Why am I  using Titanic dataset](#331)\n",
    "    1. [Aim](#32)\n",
    "    1. [Variables](#33)\n",
    "        1. [Types of Features](#331)\n",
    "            1. [Categorical](#3311)\n",
    "            1. [Ordinal](#3312)\n",
    "            1. [Continous](#3313)\n",
    "1. [ Inputs & Outputs](#4)\n",
    "    1. [Inputs ](#41)\n",
    "    1. [Outputs](#42)\n",
    "1. [Installation](#5)\n",
    "    1. [ jupyter notebook](#51)\n",
    "        1. [What browsers are supported?](#511)\n",
    "    1. [ kaggle kernel](#52)\n",
    "    \n",
    "    1. [Colab notebook](#53)\n",
    "    1. [install python & packages](#54)\n",
    "    1. [Loading Packages](#55)\n",
    "1. [Exploratory data analysis](#6)\n",
    "    1. [Data Collection](#61)\n",
    "    1. [Visualization](#62)\n",
    "        1. [Scatter plot](#621)\n",
    "        1. [Box](#622)\n",
    "        1. [Histogram](#623)\n",
    "        1. [Multivariate Plots](#624)\n",
    "        1. [Violinplots](#625)\n",
    "        1. [Pair plot](#626)\n",
    "        1. [Kde plot](#627)\n",
    "        1. [Joint plot](#628)\n",
    "        1. [Andrews curves](#629)\n",
    "        1. [Heatmap](#6210)\n",
    "        1. [Radviz](#6211)\n",
    "    1. [Data Preprocessing](#63)\n",
    "        1. [Features](#631)\n",
    "        1. [Explorer Dataset](#632)\n",
    "    1. [Data Cleaning](#64)\n",
    "        1. [Transforming Features](#641)\n",
    "        1. [Feature Encoding](#642)\n",
    "1. [Model Deployment](#7)\n",
    "    1. [Families of ML algorithms](#71)\n",
    "    1. [Prepare Features & Targets](#72)\n",
    "    1. [how to prevent overfitting &  underfitting?](#73)\n",
    "    1. [Accuracy and precision](#74)\n",
    "    1. [RandomForestClassifier](#74)\n",
    "        1. [prediction](#741)\n",
    "    1. [XGBoost](#75)\n",
    "        1. [prediction](#751)\n",
    "    1. [Logistic Regression](#76)\n",
    "        1. [prediction](#761)\n",
    "    1. [DecisionTreeRegressor ](#77)\n",
    "    1. [HuberRegressor](#78)\n",
    "    1. [ExtraTreeRegressor](#79)\n",
    "    1. [How do I submit?](#710)\n",
    "1. [Conclusion](#8)\n",
    "1. [References](#9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "750903cc2679d39058f56df6c6c040be02b748df"
   },
   "source": [
    " <a id=\"1\"></a> <br>\n",
    " <br>\n",
    "## 1- Introduction\n",
    "This is a **comprehensive ML techniques with python** , that I have spent for more than six months to complete it.\n",
    "\n",
    "It is clear that everyone in this community is familiar with titanic dataset but if you need to review your information about the dataset please visit this [link](https://www.kaggle.com/c/titanic/data).\n",
    "\n",
    "I have tried to help **beginners**  in Kaggle how to face machine learning problems. Also, I think it is a great opportunity for who want to learn machine learning workflow with python completely.\n",
    "I have covered most of the methods that are implemented for **Titanic** until **2019**, you can start to learn and review your knowledge about ML with a perfect dataset and try to learn and memorize the workflow for your journey in Data science world."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0146428e0c60dceb1f6f5f741498ebb10c319fb1"
   },
   "source": [
    " <a id=\"11\"></a> <br>\n",
    " <br>\n",
    "## 1-1 Courses\n",
    "There are a lot of online courses that can help you develop your knowledge, here I have just  listed some of them:\n",
    "\n",
    "1. [Machine Learning Certification by Stanford University (Coursera)](https://www.coursera.org/learn/machine-learning/)\n",
    "\n",
    "2. [Machine Learning A-Z™: Hands-On Python & R In Data Science (Udemy)](https://www.udemy.com/machinelearning/)\n",
    "\n",
    "3. [Deep Learning Certification by Andrew Ng from deeplearning.ai (Coursera)](https://www.coursera.org/specializations/deep-learning)\n",
    "\n",
    "4. [Python for Data Science and Machine Learning Bootcamp (Udemy)](Python for Data Science and Machine Learning Bootcamp (Udemy))\n",
    "\n",
    "5. [Mathematics for Machine Learning by Imperial College London](https://www.coursera.org/specializations/mathematics-machine-learning)\n",
    "\n",
    "6. [Deep Learning A-Z™: Hands-On Artificial Neural Networks](https://www.udemy.com/deeplearning/)\n",
    "\n",
    "7. [Complete Guide to TensorFlow for Deep Learning Tutorial with Python](https://www.udemy.com/complete-guide-to-tensorflow-for-deep-learning-with-python/)\n",
    "\n",
    "8. [Data Science and Machine Learning Tutorial with Python – Hands On](https://www.udemy.com/data-science-and-machine-learning-with-python-hands-on/)\n",
    "\n",
    "9. [Machine Learning Certification by University of Washington](https://www.coursera.org/specializations/machine-learning)\n",
    "\n",
    "10. [Data Science and Machine Learning Bootcamp with R](https://www.udemy.com/data-science-and-machine-learning-bootcamp-with-r/)\n",
    "11. [Creative Applications of Deep Learning with TensorFlow](https://www.class-central.com/course/kadenze-creative-applications-of-deep-learning-with-tensorflow-6679)\n",
    "12. [Neural Networks for Machine Learning](https://www.class-central.com/mooc/398/coursera-neural-networks-for-machine-learning)\n",
    "13. [Practical Deep Learning For Coders, Part 1](https://www.class-central.com/mooc/7887/practical-deep-learning-for-coders-part-1)\n",
    "14. [Machine Learning](https://www.cs.ox.ac.uk/teaching/courses/2014-2015/ml/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bb542dc342f6f3378ccbd1612796f45d5859d0c9"
   },
   "source": [
    " <a id=\"12\"></a> <br>\n",
    " <br>\n",
    "## 1-2 Kaggle Kernels\n",
    "I want to thanks **Kaggle team**  and  all of the **kernel's authors**  who develop this huge resources for Data Scientists. I have learned from the work of others and I have just listed some more important kernels that inspired my work and I've used them in this kernel:\n",
    "\n",
    "1. [https://www.kaggle.com/ash316/eda-to-prediction-dietanic](https://www.kaggle.com/ash316/eda-to-prediction-dietanic)\n",
    "\n",
    "2. [https://www.kaggle.com/mrisdal/exploring-survival-on-the-titanic](https://www.kaggle.com/mrisdal/exploring-survival-on-the-titanic)\n",
    "\n",
    "3. [https://www.kaggle.com/yassineghouzam/titanic-top-4-with-ensemble-modeling](https://www.kaggle.com/yassineghouzam/titanic-top-4-with-ensemble-modeling)\n",
    "\n",
    "4. [https://www.kaggle.com/ldfreeman3/a-data-science-framework-to-achieve-99-accuracy](https://www.kaggle.com/ldfreeman3/a-data-science-framework-to-achieve-99-accuracy)\n",
    "\n",
    "5. [https://www.kaggle.com/startupsci/titanic-data-science-solutions](https://www.kaggle.com/startupsci/titanic-data-science-solutions)\n",
    "6. [scikit-learn-ml-from-start-to-finish](https://www.kaggle.com/jeffd23/scikit-learn-ml-from-start-to-finish)\n",
    "<br>\n",
    "[go to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "04ea4730e0f8cc169540b3e731bc38d43f476014"
   },
   "source": [
    " <a id=\"13\"></a> <br>\n",
    " <br>\n",
    "## 1-3 Ebooks\n",
    "So you love reading , here is **10 free machine learning books:**\n",
    "1. [Probability and Statistics for Programmers](http://www.greenteapress.com/thinkstats/)\n",
    "2. [Bayesian Reasoning and Machine Learning](http://web4.cs.ucl.ac.uk/staff/D.Barber/textbook/091117.pdf)\n",
    "2. [An Introduction to Statistical Learning](http://www-bcf.usc.edu/~gareth/ISL/)\n",
    "2. [Understanding Machine Learning](http://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/index.html)\n",
    "2. [A Programmer’s Guide to Data Mining](http://guidetodatamining.com/)\n",
    "2. [Mining of Massive Datasets](http://infolab.stanford.edu/~ullman/mmds/book.pdf)\n",
    "2. [A Brief Introduction to Neural Networks](http://www.dkriesel.com/_media/science/neuronalenetze-en-zeta2-2col-dkrieselcom.pdf)\n",
    "2. [Deep Learning](http://www.deeplearningbook.org/)\n",
    "2. [Natural Language Processing with Python](https://www.researchgate.net/publication/220691633_Natural_Language_Processing_with_Python)\n",
    "2. [Machine Learning Yearning](http://www.mlyearning.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "627e2b5bdb18563aeca5e7f97f3469f1542a5f74"
   },
   "source": [
    " <a id=\"14\"></a> <br>\n",
    " <br>\n",
    "## 1-4 Cheat Sheets\n",
    "Data Science is an ever-growing field, there are numerous tools & techniques to remember. It is not possible for anyone to remember all the functions, operations and formulas of each concept. That’s why we have cheat sheets. But there are a plethora of cheat sheets available out there, choosing the right cheat sheet is a tough task.\n",
    "\n",
    "[Top 28 Cheat Sheets for Machine Learning](https://www.analyticsvidhya.com/blog/2017/02/top-28-cheat-sheets-for-machine-learning-data-science-probability-sql-big-data/)\n",
    "<br>\n",
    "###### [Go to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e11b73b618b0f6e4335520ef80267c6d577d1ba5"
   },
   "source": [
    "<a id=\"2\"></a> <br>\n",
    "## 2- Machine Learning\n",
    "Machine Learning is a field of study that gives computers the ability to learn without being explicitly programmed.\n",
    "\n",
    "**Arthur\tSamuel, 1959**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "20c66c96b3cf0abd94f514e362a80a084b9ac562"
   },
   "source": [
    " <a id=\"21\"></a> <br>\n",
    "## 2-1 Machine Learning Workflow\n",
    "\n",
    "If you have already read some [machine learning books](https://github.com/mjbahmani/10-steps-to-become-a-data-scientist/tree/master/Ebooks). You have noticed that there are different ways to stream data into machine learning.\n",
    "\n",
    "Most of these books share the following steps:\n",
    "1. Define Problem\n",
    "1. Specify Inputs & Outputs\n",
    "1. Exploratory Data Analysis\n",
    "1. Data Collection\n",
    "1. Data Preprocessing\n",
    "1. Data Cleaning\n",
    "1. Visualization\n",
    "1. Model Design, Training, and Offline Evaluation\n",
    "1. Model Deployment, Online Evaluation, and Monitoring\n",
    "1. Model Maintenance, Diagnosis, and Retraining\n",
    "\n",
    "Of course, the same solution can not be provided for all problems, so the best way is to create a **general framework** and adapt it to new problem.\n",
    "\n",
    "**You can see my workflow in the below image** :\n",
    "\n",
    " <img src=\"http://s8.picofile.com/file/8344100018/workflow3.png\" />\n",
    "\n",
    "**Data Science has so many techniques and procedures that can confuse anyone.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d8b27260d5ccff025f37490d84bd35bba7eef00a"
   },
   "source": [
    " <a id=\"22\"></a> <br>\n",
    "## 2-1 Real World Application Vs Competitions\n",
    "We all know that there are differences between real world problem and competition problem. The following figure that is taken from one of the courses in coursera, has partly made this comparison: \n",
    "\n",
    "<img src=\"http://s9.picofile.com/file/8339956300/reallife.png\" height=\"600\" width=\"500\" />\n",
    "\n",
    "As you can see, there are a lot more steps to solve  in real problems.\n",
    "###### [Go to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "600be852c0d28e7c0c5ebb718904ab15a536342c"
   },
   "source": [
    "<a id=\"3\"></a> \n",
    "<br>\n",
    "## 3- Problem Definition\n",
    "I think one of the important things when you start a new machine learning project is Defining your problem. that means you should understand business problem.( **Problem Formalization**)\n",
    "\n",
    "Problem Definition has four steps that have illustrated in the picture below:\n",
    "<img src=\"http://s8.picofile.com/file/8344103134/Problem_Definition2.png\" width=400 height=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1bef8401fc30b062fd63af4dc5a8cb6a0e1e7cad"
   },
   "source": [
    "<a id=\"31\"></a>\n",
    "<br>\n",
    "## 3-1 Problem Feature\n",
    "The sinking of the Titanic is one of the most infamous shipwrecks in history. **On April 15, 1912**, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing **1502 out of 2224** passengers and crew. That's why the name DieTanic. This is a very unforgetable disaster that no one in the world can forget.\n",
    "\n",
    "It took about $7.5 million to build the Titanic and it sunk under the ocean due to collision. The Titanic Dataset is a very good dataset for begineers to start a journey in data science and participate in competitions in Kaggle.\n",
    "\n",
    "ٌWe will use the classic titanic data set. This dataset contains information about **11 different variables**:\n",
    "<img src=\"http://s9.picofile.com/file/8340453092/Titanic_feature.png\" height=\"500\" width=\"500\">\n",
    "\n",
    "1. Survival\n",
    "1. Pclass\n",
    "1. Name\n",
    "1. Sex\n",
    "1. Age\n",
    "1. SibSp\n",
    "1. Parch\n",
    "1. Ticket\n",
    "1. Fare\n",
    "1. Cabin\n",
    "1. Embarked\n",
    "\n",
    "> <font color=\"red\"><b>Note :</b></font>\n",
    "You must answer the following question:\n",
    "How does your company expact to use and benfit from your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5b4fdff5aafeab324b00937353920d4577b3c2da"
   },
   "source": [
    "<a id=\"331\"></a> \n",
    "<a id=\"32\"></a> <br>\n",
    "### 3-2 Aim\n",
    "It is your job to predict if a **passenger** survived the sinking of the Titanic or not.  For each PassengerId in the test set, you must predict a 0 or 1 value for the Survived variable.(binary classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "47fd05d6f7e0ce47c8d4d6edae1826ced2a6ca78"
   },
   "source": [
    "<a id=\"33\"></a> <br>\n",
    "### 3-3 Variables\n",
    "\n",
    "1. **Age** :\n",
    "    1. Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n",
    "\n",
    "1. **Sibsp** :\n",
    "    1. The dataset defines family relations in this way...\n",
    "\n",
    "        a. Sibling = brother, sister, stepbrother, stepsister\n",
    "\n",
    "        b. Spouse = husband, wife (mistresses and fiancés were ignored)\n",
    "\n",
    "1. **Parch**:\n",
    "    1. The dataset defines family relations in this way...\n",
    "\n",
    "        a. Parent = mother, father\n",
    "\n",
    "        b. Child = daughter, son, stepdaughter, stepson\n",
    "\n",
    "        c. Some children travelled only with a nanny, therefore parch=0 for them.\n",
    "\n",
    "1. **Pclass** :\n",
    "    *  A proxy for socio-economic status (SES).\n",
    "        * 1st = Upper\n",
    "        * 2nd = Middle\n",
    "        * 3rd = Lower\n",
    "1. **Embarked** :\n",
    "     * nominal datatype \n",
    "1. **Name**: \n",
    "    * nominal datatype . It could be used in feature engineering to derive the gender from title\n",
    "1. **Sex**: \n",
    "   * nominal datatype \n",
    "1. **Ticket**:\n",
    "    * that have no impact on the outcome variable. Thus, they will be excluded from analysis\n",
    "1. **Cabin**: \n",
    "    * is a nominal datatype that can be used in feature engineering\n",
    "1.  **Fare**:\n",
    "    * Indicating the fare\n",
    "1. **PassengerID**:\n",
    "    * have no impact on the outcome variable. Thus, it will be excluded from analysis\n",
    "1. **Survival**:\n",
    "    * **[dependent variable](http://www.dailysmarty.com/posts/difference-between-independent-and-dependent-variables-in-machine-learning)** , 0 or 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8bb4dfebb521f83543e1d45db3559216dad8f6fb"
   },
   "source": [
    "<a id=\"4\"></a> <br>\n",
    "## 4- Inputs & Outputs\n",
    "<a id=\"41\"></a> <br>\n",
    "### 4-1 Inputs\n",
    "What's our input for this problem:\n",
    "    1. train.csv\n",
    "    1. test.csv\n",
    "<a id=\"42\"></a> <br>\n",
    "### 4-2 Outputs\n",
    "1. Your score is the percentage of passengers you correctly predict. This is known simply as \"**accuracy**”.\n",
    "\n",
    "\n",
    "The Outputs should have exactly **2 columns**:\n",
    "\n",
    "    1. PassengerId (sorted in any order)\n",
    "    1. Survived (contains your binary predictions: 1 for survived, 0 for deceased)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "89ee0cda57822cd4102eadf8992c5bfe1964d557"
   },
   "source": [
    "<a id=\"5\"></a> <br>\n",
    "## 5-Installation\n",
    "#### Windows:\n",
    "1. Anaconda (from https://www.continuum.io) is a free Python distribution for SciPy stack. It is also available for Linux and Mac.\n",
    "1. Canopy (https://www.enthought.com/products/canopy/) is available as free as well as commercial distribution with full SciPy stack for Windows, Linux and Mac.\n",
    "1. Python (x,y) is a free Python distribution with SciPy stack and Spyder IDE for Windows OS. (Downloadable from http://python-xy.github.io/)\n",
    "\n",
    "#### Linux:\n",
    "1. Package managers of respective Linux distributions are used to install one or more packages in SciPy stack.\n",
    "\n",
    "1. For Ubuntu Users:\n",
    "sudo apt-get install python-numpy python-scipy python-matplotlibipythonipythonnotebook\n",
    "python-pandas python-sympy python-nose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c1793fb141d3338bbc4300874be6ffa5cb1a9139"
   },
   "source": [
    "<a id=\"51\"></a> <br>\n",
    "## 5-1 Jupyter notebook\n",
    "I strongly recommend installing **Python** and **Jupyter** using the **[Anaconda Distribution](https://www.anaconda.com/download/)**, which includes Python, the Jupyter Notebook, and other commonly used packages for scientific computing and data science.\n",
    "\n",
    "1. First, download Anaconda. We recommend downloading Anaconda’s latest Python 3 version.\n",
    "\n",
    "2. Second, install the version of Anaconda which you downloaded, following the instructions on the download page.\n",
    "\n",
    "3. Congratulations, you have installed Jupyter Notebook! To run the notebook, run the following command at the Terminal (Mac/Linux) or Command Prompt (Windows):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "abbd1757dde9805758a2cec47a186e31dbc29822"
   },
   "source": [
    "> jupyter notebook\n",
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8a70c253d5afa93f07a7a7e048dbb2d7812c8d10"
   },
   "source": [
    "<a id=\"52\"></a> <br>\n",
    "## 5-2 Kaggle Kernel\n",
    "Kaggle kernel is an environment just like you use jupyter notebook, it's an **extension** of the where in you are able to carry out all the functions of jupyter notebooks plus it has some added tools like forking et al."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "237bbe4e4509c9491ce165e3599c432b979d7b90"
   },
   "source": [
    "<a id=\"53\"></a> <br>\n",
    "## 5-3 Colab notebook\n",
    "**Colaboratory** is a research tool for machine learning education and research. It’s a Jupyter notebook environment that requires no setup to use.\n",
    "<a id=\"531\"></a> <br>\n",
    "### 5-3-1 What browsers are supported?\n",
    "Colaboratory works with most major browsers, and is most thoroughly tested with desktop versions of Chrome and Firefox.\n",
    "<a id=\"532\"></a> <br>\n",
    "### 5-3-2 Is it free to use?\n",
    "Yes. Colaboratory is a research project that is free to use.\n",
    "<a id=\"533\"></a> <br>\n",
    "### 5-3-3 What is the difference between Jupyter and Colaboratory?\n",
    "Jupyter is the open source project on which Colaboratory is based. Colaboratory allows you to use and share Jupyter notebooks with others without having to download, install, or run anything on your own computer other than a browser.\n",
    "###### [Go to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fbedcae8843986c2139f18dad4b5f313e6535ac5"
   },
   "source": [
    "<a id=\"55\"></a> <br>\n",
    "## 5-5 Loading Packages\n",
    "In this kernel we are using the following packages:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "61f49281fdd8592b44c0867225f57e6fce36342c"
   },
   "source": [
    " <img src=\"http://s8.picofile.com/file/8338227868/packages.png\" width=400  height=400>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5bf55263fff62fb1f9d478e0e11a4038a562637f"
   },
   "source": [
    "### 5-5-1 Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pylab as pylab\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import get_dummies\n",
    "import matplotlib as mpl\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import warnings\n",
    "import sklearn\n",
    "import scipy\n",
    "import numpy\n",
    "import json\n",
    "import sys\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "795d96c03ef46bcce2f96e0e5eb8ef5c1ba7d210"
   },
   "source": [
    "### 5-5-2 Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "2c6bfbb75bf93a2eb52b34c2455c863bcd106ad8"
   },
   "outputs": [],
   "source": [
    "print('matplotlib: {}'.format(matplotlib.__version__))\n",
    "print('sklearn: {}'.format(sklearn.__version__))\n",
    "print('scipy: {}'.format(scipy.__version__))\n",
    "print('seaborn: {}'.format(sns.__version__))\n",
    "print('pandas: {}'.format(pd.__version__))\n",
    "print('numpy: {}'.format(np.__version__))\n",
    "print('Python: {}'.format(sys.version))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "187f8389fd6e034a5bb1555e3ed2fff5184a8f44"
   },
   "source": [
    "### 5-5-2 Setup\n",
    "\n",
    "A few tiny adjustments for better **code readability**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "cb7e4af0977f267f0055ef6c7b9d7081cbaeb889"
   },
   "outputs": [],
   "source": [
    "sns.set(style='white', context='notebook', palette='deep')\n",
    "pylab.rcParams['figure.figsize'] = 12,8\n",
    "warnings.filterwarnings('ignore')\n",
    "mpl.style.use('ggplot')\n",
    "sns.set_style('white')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "04ff1a533119d589baee777c21194a951168b0c7"
   },
   "source": [
    "<a id=\"6\"></a> <br>\n",
    "## 6- Exploratory Data Analysis(EDA)\n",
    "\n",
    "<img src=\"http://s9.picofile.com/file/8338476134/EDA.png\">\n",
    "\n",
    " ><font color=\"red\"><b>Note:</b></font>\n",
    " You can change the order of the above steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cedecea930b278f86292367cc28d2996a235a169"
   },
   "source": [
    "<a id=\"61\"></a> <br>\n",
    "## 6-1 Data Collection\n",
    "I start Collection Data by the training and testing datasets into Pandas DataFrames.\n",
    "###### [Go to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "9269ae851b744856bce56840637030a16a5877e1"
   },
   "outputs": [],
   "source": [
    "# import train and test to play with it\n",
    "df_train = pd.read_csv('../input/train.csv')\n",
    "df_test = pd.read_csv('../input/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7b5fd1034cd591ebd29fba1c77d342ec2b408d13"
   },
   "source": [
    "After loading the data via **pandas**, we should checkout what the content is, description and via the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "edd043f8feb76cfe51b79785302ca4936ceb7b51"
   },
   "outputs": [],
   "source": [
    "type(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "edd043f8feb76cfe51b79785302ca4936ceb7b51"
   },
   "outputs": [],
   "source": [
    "type(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "055772bd170aa8018aabd85106b76675802c33b3"
   },
   "source": [
    "<a id=\"62\"></a> <br>\n",
    "## 6-2 Visualization\n",
    " In this section I show you  **11 plots** with **matplotlib** and **seaborn** that is listed in the blew picture:\n",
    " <img src=\"http://s8.picofile.com/file/8338475500/visualization.jpg\" width=400 height=400 />\n",
    "\n",
    "###### [Go to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b0014a7a52e714996bc443981c853095926d20e5"
   },
   "source": [
    "<a id=\"621\"></a> <br>\n",
    "### 6-2-1 Scatter Plot\n",
    "\n",
    "[Scatter plot](https://en.wikipedia.org/wiki/Scatter_plot) Purpose to identify the type of relationship (if any) between two quantitative variables.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "af099546eed64ebc796403d4139cb4c977c27b03"
   },
   "outputs": [],
   "source": [
    "# Modify the graph above by assigning each species an individual color.\n",
    "g = sns.FacetGrid(df_train, hue=\"Survived\", col=\"Pclass\", margin_titles=True,\n",
    "                  palette={1:\"seagreen\", 0:\"gray\"})\n",
    "g=g.map(plt.scatter, \"Fare\", \"Age\",edgecolor=\"w\").add_legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can easily see the relationship between two variables through the following plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.plot(kind='scatter', x='Age', y='Fare',alpha = 0.5,color = 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "98c0f9c8dd185ffe7e9f2a6eb724c75ed4684802"
   },
   "outputs": [],
   "source": [
    "#show scatter plot with using Matplotlib\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(range(df_train.shape[0]), np.sort(df_train['Age'].values))\n",
    "plt.xlabel('index')\n",
    "plt.ylabel('Age')\n",
    "plt.title('Explore: Age')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d1c7b62b5f8cba427bca13049256365141655372"
   },
   "source": [
    "<a id=\"622\"></a> <br>\n",
    "### 6-2-2 Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "7b193e4aa7e6fb337d3f65c334849094addd097a"
   },
   "outputs": [],
   "source": [
    "ax= sns.boxplot(x=\"Pclass\", y=\"Age\", data=df_train)\n",
    "ax= sns.stripplot(x=\"Pclass\", y=\"Age\", data=df_train, jitter=True, edgecolor=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "743a92c3c2fff1a1f99845518247f7971ad18b7c"
   },
   "source": [
    "<a id=\"623\"></a> <br>\n",
    "### 6-2-3 Histogram\n",
    "We can also create a **histogram** of each input variable to get an idea of the **distribution**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "5da0520ed3e738ee8814b2d91843ed4acec2b6e6"
   },
   "outputs": [],
   "source": [
    "# histograms\n",
    "df_train.hist(figsize=(15,20));\n",
    "plt.figure();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b4e3de19781686010c6038f0e3076eb678398169"
   },
   "source": [
    "It looks like perhaps two of the input variables have a Gaussian distribution. This is useful to note as we can use algorithms that can exploit this assumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "9f80a6e971cbf0af72d659b51af552ea1dddc9a8"
   },
   "outputs": [],
   "source": [
    "df_train[\"Age\"].hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.Age.plot(kind = 'hist',bins = 5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "06c7ec477241ef4e5ea68e6cc09f785638b31d6f"
   },
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(1,2,figsize=(20,10))\n",
    "df_train[df_train['Survived']==0].Age.plot.hist(ax=ax[0],bins=20,edgecolor='black',color='red')\n",
    "ax[0].set_title('Survived= 0')\n",
    "x1=list(range(0,85,5))\n",
    "ax[0].set_xticks(x1)\n",
    "df_train[df_train['Survived']==1].Age.plot.hist(ax=ax[1],color='green',bins=20,edgecolor='black')\n",
    "ax[1].set_title('Survived= 1')\n",
    "x2=list(range(0,85,5))\n",
    "ax[1].set_xticks(x2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "18637e84198615d9f936d0ef62723a98aa8cf4a4"
   },
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(1,2,figsize=(18,8))\n",
    "df_train['Survived'].value_counts().plot.pie(explode=[0,0.1],autopct='%1.1f%%',ax=ax[0],shadow=True)\n",
    "ax[0].set_title('Survived')\n",
    "ax[0].set_ylabel('')\n",
    "sns.countplot('Survived',data=df_train,ax=ax[1])\n",
    "ax[1].set_title('Survived')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "4349021072da9bc4d1f1b523991e19590593d048"
   },
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(1,2,figsize=(18,8))\n",
    "df_train[['Sex','Survived']].groupby(['Sex']).mean().plot.bar(ax=ax[0])\n",
    "ax[0].set_title('Survived vs Sex')\n",
    "sns.countplot('Sex',hue='Survived',data=df_train,ax=ax[1])\n",
    "ax[1].set_title('Sex:Survived vs Dead')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "6a8c6653dad04b77a622d7ec0803b97315580d40"
   },
   "outputs": [],
   "source": [
    "sns.countplot('Pclass', hue='Survived', data=df_train)\n",
    "plt.title('Pclass: Sruvived vs Dead')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3bbff56707484f88625eb8ef309b712ba03f939e"
   },
   "source": [
    "<a id=\"624\"></a> <br>\n",
    "### 6-2-4 Multivariate Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "eb4e5d117e4ef40d7668632f42130206a5537bd0"
   },
   "outputs": [],
   "source": [
    "# scatter plot matrix\n",
    "pd.plotting.scatter_matrix(df_train,figsize=(10,10))\n",
    "plt.figure();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "de7fea7986071fafbe0b93933e3beda445cbe373"
   },
   "source": [
    "Note the diagonal grouping of some pairs of attributes. This suggests a high correlation and a predictable relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e0f696ec021ec99c1058a62e22c8b73082fe6fa7"
   },
   "source": [
    "<a id=\"625\"></a> <br>\n",
    "### 6-2-5 Violinplots\n",
    "(https://seaborn.pydata.org/generated/seaborn.violinplot.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "e352d2f8340609adf4bf6718b1d2ecee0fa730b5"
   },
   "outputs": [],
   "source": [
    "# violinplots on petal-length for each species\n",
    "sns.violinplot(data=df_train,x=\"Sex\", y=\"Age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "f9a29b9689cd5c3901f27901aa0b5295fc2f04f1"
   },
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(1,2,figsize=(18,8))\n",
    "sns.violinplot(\"Pclass\",\"Age\", hue=\"Survived\", data=df_train,split=True,ax=ax[0])\n",
    "ax[0].set_title('Pclass and Age vs Survived')\n",
    "ax[0].set_yticks(range(0,110,10))\n",
    "sns.violinplot(\"Sex\",\"Age\", hue=\"Survived\", data=df_train,split=True,ax=ax[1])\n",
    "ax[1].set_title('Sex and Age vs Survived')\n",
    "ax[1].set_yticks(range(0,110,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0ed35bceb87051e56316d35a630334518e8b8c64"
   },
   "source": [
    "<a id=\"626\"></a> <br>\n",
    "### 6-2-6 pairplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using seaborn pairplot to see the bivariate relation between each pair of features\n",
    "sns.pairplot(data=df_train[[\"Fare\",\"Survived\",\"Age\",\"Pclass\"]],\n",
    "             hue=\"Survived\", dropna=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2544d3c2dd34a360d295019d8cb597c7ef8f66bc"
   },
   "source": [
    "<a id=\"627\"></a> <br>\n",
    "###  6-2-7 kdeplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fb187bcc0fb51e53f8abe9e3952c6ae5c3177411"
   },
   "source": [
    "We can also replace the histograms shown in the diagonal of the pairplot by kde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "1d07222b89303b386e9e824d52cc73c045667f25"
   },
   "outputs": [],
   "source": [
    "sns.FacetGrid(df_train, hue=\"Survived\", size=5).map(sns.kdeplot, \"Fare\").add_legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "560d8e8f17bacefaf8c3855a9648f26b82fdee9b"
   },
   "source": [
    "<a id=\"628\"></a> <br>\n",
    "### 6-2-8 jointplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "4adb4da16ea61e0f1a12bc9925dfbbaaa81e0360"
   },
   "outputs": [],
   "source": [
    "sns.jointplot(x='Fare',y='Age',data=df_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "1b4f23fbbaf78fa34ae426c09e732286c6f6f83a"
   },
   "outputs": [],
   "source": [
    "sns.jointplot(x='Fare',y='Age' ,data=df_train, kind='reg');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3768e31e990bfe4c2ff7b45087fbba85e0560d00"
   },
   "source": [
    "<a id=\"629\"></a> <br>\n",
    "###  6-2-9 Swarm plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "263eaa9d2bfad0f8c68b6e8e874bdc11a6e802ac"
   },
   "outputs": [],
   "source": [
    "sns.swarmplot(x='Pclass',y='Age',data=df_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8e73333289d17dd648b7b2112d7fe3fe7ea444d0"
   },
   "source": [
    "<a id=\"6210\"></a> <br>\n",
    "### 6-2-10 Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "3100955ca9dc61ac7d435e9c064d10d06f26afa7"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,4)) \n",
    "sns.heatmap(df_train.corr(),annot=True,cmap='cubehelix_r') #draws  heatmap with input as the correlation matrix calculted by(iris.corr())\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(df_train.corr(), cmap='hot', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ab06d1cd799430c7c7f8de978ee2c6e275e7655b"
   },
   "source": [
    "###  6-2-11 Bar Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "329488de1a908a6d367b9da4b40a20238163d32e"
   },
   "outputs": [],
   "source": [
    "df_train['Pclass'].value_counts().plot(kind=\"bar\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3dafbfb8735b66c98088cb0e85d50d4772a06df1"
   },
   "source": [
    "### 6-2-12 Factorplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "33f7dd81d408b1530113c451dc1b58194ec487b8"
   },
   "outputs": [],
   "source": [
    "sns.factorplot('Pclass','Survived',hue='Sex',data=df_train)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "ec0eb471da47b109dafe37bafe3531e30ede4b4b"
   },
   "outputs": [],
   "source": [
    "sns.factorplot('SibSp','Survived',hue='Pclass',data=df_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "7be31ad1c83d74d75aa7cb179b6e715a63643e38"
   },
   "outputs": [],
   "source": [
    "#let's see some others factorplot\n",
    "f,ax=plt.subplots(1,2,figsize=(20,8))\n",
    "sns.barplot('SibSp','Survived', data=df_train,ax=ax[0])\n",
    "ax[0].set_title('SipSp vs Survived in BarPlot')\n",
    "sns.factorplot('SibSp','Survived', data=df_train,ax=ax[1])\n",
    "ax[1].set_title('SibSp vs Survived in FactorPlot')\n",
    "plt.close(2)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "739bba4248dec9a31b7f4f00618cd2fce103d172"
   },
   "source": [
    "### 6-2-13 Distplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "318b702bd9751c332c3ad854e7f90e685b1417f5"
   },
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(1,3,figsize=(20,8))\n",
    "sns.distplot(df_train[df_train['Pclass']==1].Fare,ax=ax[0])\n",
    "ax[0].set_title('Fares in Pclass 1')\n",
    "sns.distplot(df_train[df_train['Pclass']==2].Fare,ax=ax[1])\n",
    "ax[1].set_title('Fares in Pclass 2')\n",
    "sns.distplot(df_train[df_train['Pclass']==3].Fare,ax=ax[2])\n",
    "ax[2].set_title('Fares in Pclass 3')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5af51158a5bc342947c553392e3d1665ac24ba62"
   },
   "source": [
    "### 6-2-12 Conclusion\n",
    "We have used Python to apply data visualization tools to theTitanic dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "91dda1f631cf4ed362162501aaaac6d19cfd6cc7"
   },
   "source": [
    "<a id=\"63\"></a> <br>\n",
    "## 6-3 Data Preprocessing\n",
    "\n",
    "\n",
    "###### [Go to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "73ab30f86273b590a51fc363d9bf78c2709558fa"
   },
   "source": [
    "<a id=\"632\"></a> <br>\n",
    "## 6-3-2 Explorer Dataset\n",
    "\n",
    "\n",
    "###### [Go to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "4b45251be7be77333051fe738639104ae1005fa5"
   },
   "outputs": [],
   "source": [
    "# shape\n",
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "c64e9d3e0bf394fb833de94a0fc5c34f69fce24c"
   },
   "outputs": [],
   "source": [
    "#columns*rows\n",
    "df_train.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a6315bf510cecb907b2d23aad25faf6ccad32ac4"
   },
   "source": [
    ">  <font color=\"red\"><b>Note:</b></font>\n",
    "how many NA elements in every column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "675f72fb58d83c527f71819e71ed8e17f81126f5"
   },
   "outputs": [],
   "source": [
    "##df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d1eb374a6707aa3246f0581481aa177b87d9f580"
   },
   "outputs": [],
   "source": [
    "def check_missing_data(df):\n",
    "    flag=df.isna().sum().any()\n",
    "    if flag==True:\n",
    "        total = df.isnull().sum()\n",
    "        percent = (df.isnull().sum())/(df.isnull().count()*100)\n",
    "        output = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "        data_type = []\n",
    "        # written by MJ Bahmani\n",
    "        for col in df.columns:\n",
    "            dtype = str(df[col].dtype)\n",
    "            data_type.append(dtype)\n",
    "        output['Types'] = data_type\n",
    "        return(np.transpose(output))\n",
    "    else:\n",
    "        return(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2ce3a485a66b6ca852b62936ce042301f66e165b"
   },
   "outputs": [],
   "source": [
    "check_missing_data(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d87e4566589d12ac869112a384f68a4f9704c4fc"
   },
   "outputs": [],
   "source": [
    "check_missing_data(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "414a457068cc1e0390f7be45ad85cab0cab3cb72"
   },
   "source": [
    "If you want to remove all the null value, you can uncomment this line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "e8e124ca20643ad307d9bfdc34328d548c6ddcbc"
   },
   "outputs": [],
   "source": [
    "# remove rows that have NA's\n",
    "#train = train.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "277e1998627d6a3ddeff4e913a6b8c3dc81dec96"
   },
   "source": [
    "\n",
    "We can get a quick idea of how many instances (rows) and how many attributes (columns) the data contains with the shape property.\n",
    "\n",
    "You should see **891** instances and **12** attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ec0bcddca314cc88735004059a34c991d4d63611"
   },
   "outputs": [],
   "source": [
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "95ee5e18f97bc410df1e54ac74e32cdff2b30755"
   },
   "source": [
    ">  <font color=\"red\"><b>Note:</b></font>\n",
    "for getting some information about the dataset you can use **info()** command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "ca840f02925751186f87e402fcb5f637ab1ab8a0"
   },
   "outputs": [],
   "source": [
    "print(df_train.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3458838205be4c7fbff88e95ef69934e13e2199b"
   },
   "source": [
    ">  <font color=\"red\"><b>Note:</b></font>\n",
    "you see number of unique item for **Age** and **Pclass** with command below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "4b90d165a007106ae99809ad28edd75bd8153dd8"
   },
   "outputs": [],
   "source": [
    "df_train['Age'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "8accfbddf2228274ad412c3ad3be72b4107d6f6c"
   },
   "outputs": [],
   "source": [
    "df_train[\"Pclass\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ae08b544a8d4202c7d0a47ec83d685e81c91a66d"
   },
   "source": [
    "To check the first 5 rows of the data set, we can use head(5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "5899889553c3416b27e93efceddb106eb71f5156"
   },
   "outputs": [],
   "source": [
    "df_train.head(5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1150b6ac3d82562aefd5c64f9f01accee5eace4d"
   },
   "source": [
    "To check out last 5 row of the data set, we use tail() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "79339442ff1f53ae1054d794337b9541295d3305"
   },
   "outputs": [],
   "source": [
    "df_train.tail() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2c288c3dc8656a872a8529368812546e434d3a22"
   },
   "source": [
    "To pop up 5 random rows from the data set, we can use **sample(5)**  function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "09eb18d1fcf4a2b73ba2f5ddce99dfa521681140"
   },
   "outputs": [],
   "source": [
    "df_train.sample(5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c8a1cc36348c68fb98d6cb28aa9919fc5f2892f3"
   },
   "source": [
    "To give a statistical summary about the dataset, we can use **describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "3f7211e96627b9a81c5b620a9ba61446f7719ea3"
   },
   "outputs": [],
   "source": [
    "df_train.describe() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "031d16ca235837e889734635ecff193be64b27a4"
   },
   "source": [
    "To check out how many null info are on the dataset, we can use **isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "8807b632269e2fa734ad26e8513199400fc09a83"
   },
   "outputs": [],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "446e6162e16325213047ff31454813455668b574"
   },
   "outputs": [],
   "source": [
    "df_train.groupby('Survived').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c2f1eaf0b6dfdc7cc4dace04614e99ed56425d00"
   },
   "source": [
    "To print dataset **columns**, we can use columns atribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "909d61b33ec06249d0842e6115597bbacf21163f"
   },
   "outputs": [],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "22bc5d81c18275ee1fb082c0adbb7a65bdbec4cc"
   },
   "source": [
    ">  <font color=\"red\"><b>Note:</b></font>\n",
    "In pandas's data frame you can perform some query such as \"where\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "c8c8d9fd63d9bdb601183aeb4f1435affeb8a596"
   },
   "outputs": [],
   "source": [
    "df_train.where(df_train['Age']==30).head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "33fc33a18489b438a884819d99dc00a02b113be8"
   },
   "source": [
    "As you can see in the below in python, it is so easy perform some query on the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "8b545ff7e8367c5ab9c1db710f70b6936ac8422c"
   },
   "outputs": [],
   "source": [
    "df_train[df_train['Age']==30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "01ea12a506f04cf995b64c9944f71fc3949ff220"
   },
   "source": [
    "Seperating the data into dependent and independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "1c92b300076a232321c915857d8a7c5685a97865"
   },
   "outputs": [],
   "source": [
    "X = df_train.iloc[:, :-1].values\n",
    "y = df_train.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "aa882e5bcdc7d5f440489eff75d1d225269655a4"
   },
   "source": [
    ">  <font color=\"red\"><b>Note:</b></font>\n",
    "Preprocessing and generation pipelines depend on a model type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8280749a19af32869978c61941d1dea306632d71"
   },
   "source": [
    "<a id=\"64\"></a> <br>\n",
    "## 6-4 Data Cleaning \n",
    "\n",
    "\n",
    "###### [Go to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "166e019ad0c531d7b82447eadbd61fb09a062047"
   },
   "source": [
    "<a id=\"641\"></a> <br>\n",
    "## 6-4-1 Transforming Features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "460e83e7cdb3db098cff0a82432a729619aac918"
   },
   "source": [
    "<a id=\"642\"></a> <br>\n",
    "## 6-4-2 Feature Encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "babcb0a6523046000101b51ba3e813313d299ec0"
   },
   "outputs": [],
   "source": [
    "def encode_features(df_train, df_test):\n",
    "    features = ['Fare', 'Cabin', 'Age', 'Sex', 'Lname', 'NamePrefix']\n",
    "    df_combined = pd.concat([df_train[features], df_test[features]])\n",
    "    \n",
    "    for feature in features:\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le = le.fit(df_combined[feature])\n",
    "        df_train[feature] = le.transform(df_train[feature])\n",
    "        df_test[feature] = le.transform(df_test[feature])\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "72cc7c7b60a33390a85b16bc34e3b9e424650cdd"
   },
   "source": [
    "<a id=\"7\"></a> <br>\n",
    "## 7- Model Deployment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "b06cb1191a0f52a904c52a918d1f999536e79bda"
   },
   "outputs": [],
   "source": [
    "#Encode Dataset\n",
    "df_train, df_test = encode_features(df_train, df_test)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "337b8b659a9c6d027bf9bcdd13a2599fbfb3458a"
   },
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7b6aa3e1e00043b658ba2111f4296c598a3ccfd2"
   },
   "source": [
    "Prepare X(features) , y(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "78abd46dab662d9e81e4dac47c83fa1df3429e32"
   },
   "outputs": [],
   "source": [
    "x_all = df_train.drop(['Survived', 'PassengerId'], axis=1)\n",
    "y_all = df_train['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0921e1c0ee59db81f42300294bc37428659a2ce9"
   },
   "outputs": [],
   "source": [
    "num_test = 0.3\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_all, y_all, test_size=num_test, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f36542f64cfec03ddefa3116a2fd033bf12c8ab8"
   },
   "outputs": [],
   "source": [
    "result=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "855fe3c46fa4fe0a1f776c644694b47093616617"
   },
   "source": [
    "<a id=\"74\"></a> <br>\n",
    "## 7-4 RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "471ac0e11bf734968a6d3152dfb35eb33695da64"
   },
   "outputs": [],
   "source": [
    "# Choose the type of classifier. \n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "# Choose some parameter combinations to try\n",
    "parameters = {'n_estimators': [4, 6, 9], \n",
    "              'max_features': ['log2', 'sqrt','auto'], \n",
    "              'criterion': ['entropy', 'gini'],\n",
    "              'max_depth': [2, 3, 5, 10], \n",
    "              'min_samples_split': [2, 3, 5],\n",
    "              'min_samples_leaf': [1,5,8]\n",
    "             }\n",
    "\n",
    "# Type of scoring used to compare parameter combinations\n",
    "acc_scorer = make_scorer(accuracy_score)\n",
    "\n",
    "# Run the grid search\n",
    "grid_obj = GridSearchCV(rfc, parameters, scoring=acc_scorer)\n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# Set the clf to the best combination of parameters\n",
    "rfc = grid_obj.best_estimator_\n",
    "\n",
    "# Fit the best algorithm to the data. \n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c0c4ce2da9cb78411e21f7c67b21da5473b01d8a"
   },
   "source": [
    "<a id=\"741\"></a> <br>\n",
    "## 7-4-1 Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "402d8924cbacc83edce356b89a268c24820ea637"
   },
   "outputs": [],
   "source": [
    "rfc_prediction = rfc.predict(X_test)\n",
    "rfc_score=accuracy_score(y_test, rfc_prediction)\n",
    "print(rfc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0bbce674c5f9c0f25f37f24c46f5effc1129dfd0"
   },
   "source": [
    "<a id=\"75\"></a> <br>\n",
    "## 7-5 XGBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f4a86e079308436741b02b813c47f2eb467def18"
   },
   "outputs": [],
   "source": [
    "xgboost = xgb.XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.05).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a09c6cd1fdc4914c928a706f47bc3abb31e1865f"
   },
   "source": [
    "<a id=\"751\"></a> <br>\n",
    "## 7-5-1 Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ae942009092c5316cc3264b9030ba98e355ec263"
   },
   "outputs": [],
   "source": [
    "xgb_prediction = xgboost.predict(X_test)\n",
    "xgb_score=accuracy_score(y_test, xgb_prediction)\n",
    "print(xgb_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3d240a0df576395a9c08df161df732bba89fda1e"
   },
   "source": [
    "<a id=\"76\"></a> <br>\n",
    "## 7-6 Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "70478a52a315460748cce36779e25dbb4d109258"
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2d02b551619c6a02aa6e62b4c2c9e019c0b72b7e"
   },
   "source": [
    "<a id=\"761\"></a> <br>\n",
    "## 7-6-1 Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "a0fb319adb2974342f5825b77cedfb7969d06fda"
   },
   "outputs": [],
   "source": [
    "logreg_prediction = logreg.predict(X_test)\n",
    "logreg_score=accuracy_score(y_test, logreg_prediction)\n",
    "print(logreg_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "452bdee0f7c81124b09f5c95ba145f852270873d"
   },
   "source": [
    "<a id=\"77\"></a> <br>\n",
    "## 7-7 DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "c65ffc653c2aee30024621c9f631c8143d47edd7"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Define model. Specify a number for random_state to ensure same results each run\n",
    "dt = DecisionTreeRegressor(random_state=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "408cb3c25edb3302a85925e997b6ce4df228293b"
   },
   "outputs": [],
   "source": [
    "# Fit model\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "7e1080c5d827c84e710b1ca60de03c87c7b73d65"
   },
   "outputs": [],
   "source": [
    "dt_prediction = dt.predict(X_test)\n",
    "dt_score=accuracy_score(y_test, dt_prediction)\n",
    "print(dt_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1b3c9ad3e462123a61a3521452f89e7774b09b54"
   },
   "source": [
    "<a id=\"79\"></a> <br>\n",
    "## 7-9 ExtraTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f63cbd4fac2937cf894d7b9f2bc0d19d8eb2b305"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import ExtraTreeRegressor\n",
    "# Define model. Specify a number for random_state to ensure same results each run\n",
    "etr = ExtraTreeRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ca66f47429954ab793fdfa80908ecb48da699f7c"
   },
   "outputs": [],
   "source": [
    "# Fit model\n",
    "etr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "56364b91268c1958b73a340aeadbfce3946d1b6c"
   },
   "outputs": [],
   "source": [
    "etr_prediction = etr.predict(X_test)\n",
    "etr_score=accuracy_score(y_test, etr_prediction)\n",
    "print(etr_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "74a2db1710f179eb22a83be6a74f28c4738ee09b"
   },
   "source": [
    "<a id=\"710\"></a> <br>\n",
    "## 7-10 How Do I Submit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0bc43f4fb0a9f48cebee4a5a97b3d1db9f8dac72"
   },
   "outputs": [],
   "source": [
    "X_train = df_train.drop(\"Survived\",axis=1)\n",
    "y_train = df_train[\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "895a1a5ba25d1d23c44c0ba02491c85a87ae3357"
   },
   "outputs": [],
   "source": [
    "X_train = X_train.drop(\"PassengerId\",axis=1)\n",
    "X_test  = df_test.drop(\"PassengerId\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e1fbc9132b9041426924d2dab2de3a39a55eab5b"
   },
   "outputs": [],
   "source": [
    "xgboost = xgb.XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.05).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "21e3a78754a191d39098c90279db1fa706b54e97"
   },
   "outputs": [],
   "source": [
    "Y_pred = xgboost.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a21f57e03827d2d2823e3d1ee02774a73424755a"
   },
   "source": [
    "You can change your model and submit the results of other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "935ba2bb107a221bac4a81e956f6c45e6d7ec380"
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": df_test[\"PassengerId\"],\n",
    "        \"Survived\": Y_pred\n",
    "    })\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "97adc471c068fbd8d36ca19a4db0d98b0924c731"
   },
   "source": [
    "-----------------\n",
    "<a id=\"8\"></a> <br>\n",
    "# 8- Conclusion\n",
    "I have tried to cover all the parts related to the process of **Machine Learning** with a variety of python packages and I know that there are still some problems then I hope to get your feedback to improve it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cf3679a51c72dbe2d2549b5fe97e4ac5f1fa0fa0"
   },
   "source": [
    "You can Fork and Run this kernel on Github:\n",
    "> ###### [ GitHub](https://github.com/mjbahmani/Machine-Learning-Workflow-with-Python)\n",
    "\n",
    "--------------------------------------\n",
    "\n",
    " **I hope you find this kernel helpful and some <font color=\"red\"><b>UPVOTES</b></font> would be very much appreciated** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "source": [
    "<a id=\"9\"></a> <br>\n",
    "\n",
    "-----------\n",
    "\n",
    "# 9- References\n",
    "1. [https://skymind.ai/wiki/machine-learning-workflow](https://skymind.ai/wiki/machine-learning-workflow)\n",
    "\n",
    "1. [Problem-define](https://machinelearningmastery.com/machine-learning-in-python-step-by-step/)\n",
    "\n",
    "1. [Sklearn](http://scikit-learn.org/)\n",
    "\n",
    "1. [machine-learning-in-python-step-by-step](https://machinelearningmastery.com/machine-learning-in-python-step-by-step/)\n",
    "\n",
    "1. [Data Cleaning](http://wp.sigmod.org/?p=2288)\n",
    "\n",
    "1. [competitive data science](https://www.coursera.org/learn/competitive-data-science/)\n",
    "\n",
    "1. [Machine Learning Certification by Stanford University (Coursera)](https://www.coursera.org/learn/machine-learning/)\n",
    "\n",
    "1. [Machine Learning A-Z™: Hands-On Python & R In Data Science (Udemy)](https://www.udemy.com/machinelearning/)\n",
    "\n",
    "1. [Deep Learning Certification by Andrew Ng from deeplearning.ai (Coursera)](https://www.coursera.org/specializations/deep-learning)\n",
    "\n",
    "1. [Python for Data Science and Machine Learning Bootcamp (Udemy)](Python for Data Science and Machine Learning Bootcamp (Udemy))\n",
    "\n",
    "1. [Mathematics for Machine Learning by Imperial College London](https://www.coursera.org/specializations/mathematics-machine-learning)\n",
    "\n",
    "1. [Deep Learning A-Z™: Hands-On Artificial Neural Networks](https://www.udemy.com/deeplearning/)\n",
    "\n",
    "1. [Complete Guide to TensorFlow for Deep Learning Tutorial with Python](https://www.udemy.com/complete-guide-to-tensorflow-for-deep-learning-with-python/)\n",
    "\n",
    "1. [Data Science and Machine Learning Tutorial with Python – Hands On](https://www.udemy.com/data-science-and-machine-learning-with-python-hands-on/)\n",
    "\n",
    "1. [Machine Learning Certification by University of Washington](https://www.coursera.org/specializations/machine-learning)\n",
    "\n",
    "1. [Data Science and Machine Learning Bootcamp with R](https://www.udemy.com/data-science-and-machine-learning-bootcamp-with-r/)\n",
    "\n",
    "1. [Creative Applications of Deep Learning with TensorFlow](https://www.class-central.com/course/kadenze-creative-applications-of-deep-learning-with-tensorflow-6679)\n",
    "\n",
    "1. [Neural Networks for Machine Learning](https://www.class-central.com/mooc/398/coursera-neural-networks-for-machine-learning)\n",
    "\n",
    "1. [Practical Deep Learning For Coders, Part 1](https://www.class-central.com/mooc/7887/practical-deep-learning-for-coders-part-1)\n",
    "\n",
    "1. [Machine Learning](https://www.cs.ox.ac.uk/teaching/courses/2014-2015/ml/index.html)\n",
    "\n",
    "1. [https://www.kaggle.com/ash316/eda-to-prediction-dietanic](https://www.kaggle.com/ash316/eda-to-prediction-dietanic)\n",
    "\n",
    "1. [https://www.kaggle.com/mrisdal/exploring-survival-on-the-titanic](https://www.kaggle.com/mrisdal/exploring-survival-on-the-titanic)\n",
    "\n",
    "1. [https://www.kaggle.com/yassineghouzam/titanic-top-4-with-ensemble-modeling](https://www.kaggle.com/yassineghouzam/titanic-top-4-with-ensemble-modeling)\n",
    "\n",
    "1. [https://www.kaggle.com/ldfreeman3/a-data-science-framework-to-achieve-99-accuracy](https://www.kaggle.com/ldfreeman3/a-data-science-framework-to-achieve-99-accuracy)\n",
    "\n",
    "1. [https://www.kaggle.com/startupsci/titanic-data-science-solutions](https://www.kaggle.com/startupsci/titanic-data-science-solutions)\n",
    "\n",
    "1. [Top 28 Cheat Sheets for Machine Learning](https://www.analyticsvidhya.com/blog/2017/02/top-28-cheat-sheets-for-machine-learning-data-science-probability-sql-big-data/)\n",
    "1. [xenonstack](https://www.xenonstack.com/blog/data-science/preparation-wrangling-machine-learning-deep/)\n",
    "1. [towardsdatascience](https://towardsdatascience.com/encoding-categorical-features-21a2651a065c)\n",
    "1. [train-test-split-and-cross-validation](https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6)\n",
    "1. [what-is-underfitting-and-overfitting](https://medium.com/greyatom/what-is-underfitting-and-overfitting-in-machine-learning-and-how-to-deal-with-it-6803a989c76)\n",
    "1. [permutation-importance](https://www.kaggle.com/dansbecker/permutation-importance)\n",
    "1. [partial-plots](https://www.kaggle.com/dansbecker/partial-plots)\n",
    "-------------\n",
    "\n",
    "###### [Go to top](#top)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
